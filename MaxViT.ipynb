{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWIHDdBv-2j9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "base_dir = \"/content/tiny-imagenet-200\"\n",
        "val_dir = os.path.join(base_dir, \"val\")\n",
        "images_dir = os.path.join(val_dir, \"images\")\n",
        "ann_file = os.path.join(val_dir, \"val_annotations.txt\")\n",
        "\n",
        "# Read annotations\n",
        "with open(ann_file) as f:\n",
        "    annotations = [line.strip().split('\\t') for line in f]\n",
        "\n",
        "# Create class folders and move images\n",
        "for img, cls, *_ in annotations:\n",
        "    cls_dir = os.path.join(val_dir, cls)\n",
        "    os.makedirs(cls_dir, exist_ok=True)\n",
        "    shutil.move(\n",
        "        os.path.join(images_dir, img),\n",
        "        os.path.join(cls_dir, img)\n",
        "    )\n",
        "\n",
        "os.rmdir(images_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ybz5B8IgMEDO",
        "outputId": "74c392c6-a4b4-4a7a-aa4d-2b0b91ea696b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.7/620.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m111.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.37.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.20.0 which is incompatible.\n",
            "opencv-contrib-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.13.0.92 requires numpy>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fin-XCH9_A7m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfla\n",
        "import tensorflow.keras.models as tfm\n",
        "import tensorflow.keras.optimizers as tfo\n",
        "import tensorflow.keras.losses as tflo\n",
        "import matplotlib.pyplot as plt\n",
        "from official.vision.ops import augment\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzYteQVT_IvJ",
        "outputId": "3ef8596f-ec26-41d5-8ac4-9bff2404bbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100000 files belonging to 200 classes.\n",
            "Found 10000 files belonging to 200 classes.\n"
          ]
        }
      ],
      "source": [
        "with open(\"tiny-imagenet-200/wnids.txt\") as f:\n",
        "    wnids = [line.strip() for line in f]\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/train\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(256, 256),\n",
        "    batch_size=None,\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"tiny-imagenet-200/val\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"categorical\",\n",
        "    class_names=wnids,\n",
        "    image_size=(224, 224),\n",
        "    batch_size=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPYNobDh_Kus"
      },
      "outputs": [],
      "source": [
        "def crop_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  image = tf.image.random_crop(image, (224, 224, 3))\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHuBokKV_PMi"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(crop_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F08edDk2_Q8I"
      },
      "outputs": [],
      "source": [
        "def apply_randaugment(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  augmenter = augment.RandAugment(num_layers=2, magnitude=9)\n",
        "  return augmenter.distort(image), label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKCtWfq8_S__"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(apply_randaugment, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tojqq9C8_U5q"
      },
      "outputs": [],
      "source": [
        "def normalise_image(image, label):\n",
        "  # image shape: [h, w, c]\n",
        "  # label shape: [num_class,]\n",
        "  mean = tf.constant([0.485, 0.456, 0.406])\n",
        "  std = tf.constant([0.229, 0.224, 0.225])\n",
        "\n",
        "  image = (image / 255.0 - mean) / std\n",
        "\n",
        "  return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQN5Kgvy_Wye"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.map(normalise_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7RLe80s_YU7"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.batch(128)\n",
        "combined_ds = train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7dVrfHK_aBp"
      },
      "outputs": [],
      "source": [
        "def mixup(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  images_lam = tf.reshape(lam, [-1, 1, 1, 1])\n",
        "  labels_lam = lam\n",
        "\n",
        "\n",
        "  images = images_lam * images + (1 - images_lam) * shuffled_images\n",
        "  labels = labels_lam * labels + (1 - labels_lam) * shuffled_labels\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uExL-9r_cFs"
      },
      "outputs": [],
      "source": [
        "mixup_ds = train_ds.map(mixup, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(mixup_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlzYm_43_eC6"
      },
      "outputs": [],
      "source": [
        "def cutmix(images, labels):\n",
        "  # images shape: [batchsize, h, w, c]\n",
        "  # labels shape: [batchsize, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  gamma_1 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  gamma_2 = tf.random.gamma(shape=[batch_size, 1], alpha=0.2)\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = gamma_1 / (gamma_1 + gamma_2)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  cut_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  cut_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(cut_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - cut_height // 2, tf.int32)\n",
        "  cut_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_x = cut_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(cut_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - cut_width // 2, tf.int32)\n",
        "  cut_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  cut_centre_y = cut_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(cut_centre_x, tf.int32) - cut_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(cut_centre_x, tf.int32) + cut_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(cut_centre_y, tf.int32) - cut_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(cut_centre_y, tf.int32) + cut_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  indices = tf.random.shuffle(tf.range(batch_size))\n",
        "  shuffled_images = tf.gather(images, indices)\n",
        "  shuffled_labels = tf.gather(labels, indices)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32) + shuffled_images * tf.cast(mask, dtype=tf.float32)\n",
        "  labels = labels * (1.0 - lam) + shuffled_labels * lam\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAa9qHHw_fm_"
      },
      "outputs": [],
      "source": [
        "cutmix_ds = train_ds.map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(cutmix_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGE4neLd_iDl"
      },
      "outputs": [],
      "source": [
        "def erase(images, labels):\n",
        "  # images shape: [batch_size, h, w, c]\n",
        "  # labels shape: [batch_size, num_class]\n",
        "  batch_size = tf.shape(images)[0]\n",
        "  img_height = tf.shape(images)[1]\n",
        "  img_width = tf.shape(images)[2]\n",
        "\n",
        "  # lam is the cut percentage with shape: [batch_size, 1]\n",
        "  lam = tf.random.uniform(shape=(batch_size, 1), minval=0.2, maxval=0.5, dtype=tf.float32)\n",
        "\n",
        "  # we find the cut image height and width all with shape [batch_size, 1]\n",
        "  erase_height = tf.cast(tf.cast(img_height, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "  erase_width = tf.cast(tf.cast(img_width, tf.float32) * tf.sqrt(lam), tf.int32)\n",
        "\n",
        "  min_height = tf.cast(erase_height // 2, tf.int32)\n",
        "  max_height = tf.cast(img_height - 1 - erase_height // 2, tf.int32)\n",
        "  erase_centre_x = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_x = erase_centre_x * tf.cast(max_height - min_height, tf.float32) + tf.cast(min_height, tf.float32)\n",
        "\n",
        "  min_width = tf.cast(erase_width // 2, tf.int32)\n",
        "  max_width = tf.cast(img_width - 1 - erase_width // 2, tf.int32)\n",
        "  erase_centre_y = tf.random.uniform(shape=(batch_size, 1), minval=0, maxval=1,\n",
        "                                   dtype=tf.float32)\n",
        "  erase_centre_y = erase_centre_y * tf.cast(max_width - min_width, tf.float32) + tf.cast(min_width, tf.float32)\n",
        "\n",
        "  # find four conors for rectangles all with shape: [batch_size, 1]\n",
        "  x1 = tf.cast(tf.cast(erase_centre_x, tf.int32) - erase_height // 2, tf.int32)\n",
        "  x2 = tf.cast(tf.cast(erase_centre_x, tf.int32) + erase_height // 2, tf.int32)\n",
        "  y1 = tf.cast(tf.cast(erase_centre_y, tf.int32) - erase_width // 2, tf.int32)\n",
        "  y2 = tf.cast(tf.cast(erase_centre_y, tf.int32) + erase_width // 2, tf.int32)\n",
        "\n",
        "  x_indices = tf.range(img_height)\n",
        "  y_indices = tf.range(img_width)\n",
        "  y_grid, x_grid = tf.meshgrid(y_indices, x_indices)\n",
        "  x_grid = tf.reshape(x_grid, [1, img_height, img_width])\n",
        "  y_grid = tf.reshape(y_grid, [1, img_height, img_width])\n",
        "\n",
        "  x1 = tf.reshape(x1, [batch_size, 1, 1])\n",
        "  x2 = tf.reshape(x2, [batch_size, 1, 1])\n",
        "  y1 = tf.reshape(y1, [batch_size, 1, 1])\n",
        "  y2 = tf.reshape(y2, [batch_size, 1, 1])\n",
        "\n",
        "  # mask matrix with shape : [batch_size, h, w]\n",
        "  mask = tf.logical_and(tf.logical_and(x1 <= x_grid, x_grid <= x2), tf.logical_and(\n",
        "      y1 <= y_grid, y_grid <= y2))\n",
        "  mask = tf.cast(mask, dtype=tf.int32)\n",
        "\n",
        "  mask = tf.reshape(mask, [batch_size, img_height, img_width, 1])\n",
        "\n",
        "  images = images * tf.cast(1 - mask, dtype=tf.float32)\n",
        "\n",
        "  return images, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxXZH2Mk_jtY"
      },
      "outputs": [],
      "source": [
        "erase_ds = train_ds.map(erase, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "combined_ds = combined_ds.concatenate(erase_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PNaEI6T_lHV"
      },
      "outputs": [],
      "source": [
        "def label_smoothing(labels, epsilon=0.1):\n",
        "  num_class = tf.cast(tf.shape(labels)[1], tf.float32)\n",
        "  return labels * (1.0 - epsilon) + epsilon / num_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhOttsWb_mum"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.map(lambda images, labels: (images, label_smoothing(labels)), num_parallel_calls=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EX2ULNuTs8g"
      },
      "outputs": [],
      "source": [
        "combined_ds = combined_ds.shuffle(buffer_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TxqfZlF_ood"
      },
      "outputs": [],
      "source": [
        "def window_partition(x, window_size):\n",
        "  # x shape:[B, H, W, C]\n",
        "  B = tf.shape(x)[0]\n",
        "  H = tf.shape(x)[1]\n",
        "  W = tf.shape(x)[2]\n",
        "  C = tf.shape(x)[3]\n",
        "\n",
        "  # x shape:[B, row_num, row_in_window, col_num, col_in_window, C]\n",
        "  x = tf.reshape(x, shape=[B, H // window_size, window_size, W // window_size, window_size, C])\n",
        "\n",
        "  # x shape:[B, row_num, col_num, row_in_window, col_in_window, C]\n",
        "  x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n",
        "\n",
        "  # x shape:[B_, row_in_window, col_in_window, C]\n",
        "  x = tf.reshape(x, shape=[-1, window_size, window_size, C])\n",
        "\n",
        "  # return shape:[B_, window_size, window_size, C] B_ is the total number of windows within a batch\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnSRnEBtB4eo"
      },
      "outputs": [],
      "source": [
        "def window_reverse(x, window_size, H, W):\n",
        "  # x shape:[B_, window_size, window_size, C] B_ is the total number of windows within a batch\n",
        "  row_num = H // window_size\n",
        "  col_num = W // window_size\n",
        "  C = tf.shape(x)[3]\n",
        "\n",
        "  # x shape:[B, row_num, col_num, row_in_window, col_in_window, C]\n",
        "  x = tf.reshape(x, shape=[-1, row_num, col_num, window_size, window_size, C])\n",
        "\n",
        "  # x shape:[B, row_num, row_in_window, col_num, col_in_window, C]\n",
        "  x = tf.transpose(x, perm=[0, 1, 3, 2, 4, 5])\n",
        "\n",
        "  # x shape:[B, H, W, C]\n",
        "  x = tf.reshape(x, shape=[-1, H, W, C])\n",
        "\n",
        "  # return shape:[B, H, W, C]\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OopwiEzSEidD"
      },
      "outputs": [],
      "source": [
        "class window_attention(tfla.Layer):\n",
        "  def __init__(self, window_size, C, num_heads):\n",
        "    super().__init__()\n",
        "    self.C = C\n",
        "    self.num_heads = num_heads\n",
        "    self.window_size = window_size\n",
        "    self.head_dims = C // num_heads\n",
        "    self.scale = tf.cast(self.head_dims, tf.float32) ** -0.5\n",
        "\n",
        "    self.qkv = tfla.Dense(3 * C)\n",
        "    self.dense = tfla.Dense(C)\n",
        "    self.rel_pos_num = (window_size * 2 - 1) * (window_size * 2 - 1)\n",
        "    # rel_pos_bias shape:[rel_pos_num, num_heads]\n",
        "    self.rel_pos_bias = self.add_weight(\n",
        "        shape=[self.rel_pos_num, num_heads],\n",
        "        initializer=tf.random_normal_initializer(stddev=0.02),\n",
        "        trainable=True\n",
        "    )\n",
        "\n",
        "    self.coord_x = tf.range(window_size)\n",
        "    self.coord_y = tf.range(window_size)\n",
        "\n",
        "    # coord shape:[2, window_size, window_size]\n",
        "    self.coord = tf.stack(tf.meshgrid(self.coord_x, self.coord_y, indexing=\"ij\"))\n",
        "    # coord shape:[2, N]\n",
        "    self.coord = tf.reshape(self.coord, shape=[2, -1])\n",
        "    # coord shape:[2, N, N]\n",
        "    self.coord = self.coord[:,None,:] - self.coord[:, :, None]\n",
        "\n",
        "    # rel_pos_h, rel_pos_w shape:[N, N]\n",
        "    self.rel_pos_h = self.coord[0, :, :] + window_size - 1\n",
        "    self.rel_pos_w = self.coord[1, :, :] + window_size - 1\n",
        "\n",
        "    # rel_pos shape:[N, N]\n",
        "    self.rel_pos = self.rel_pos_h * (2 * window_size - 1) + self.rel_pos_w\n",
        "\n",
        "  def call(self, x):\n",
        "    # x shape:[B_, window_size, window_size, C]\n",
        "    B_ = tf.shape(x)[0]\n",
        "\n",
        "    # x shape:[B_, N, C]\n",
        "    x = tf.reshape(x, shape=[B_, self.window_size * self.window_size, self.C])\n",
        "\n",
        "    N = self.window_size * self.window_size\n",
        "    # qkv shape:[B_, N, 3 * C]\n",
        "    qkv = self.qkv(x)\n",
        "    # qkv shape:[B_, N, 3, num_heads, head_dims]\n",
        "    qkv = tf.reshape(qkv, shape=[B_, N, 3, self.num_heads, self.head_dims])\n",
        "    # qkv shape:[3, B_, num_heads, N, head_dims]\n",
        "    qkv = tf.transpose(qkv, perm=[2, 0, 3, 1, 4])\n",
        "\n",
        "    # q, k, v shape:[B_, num_heads, N, head_dims]\n",
        "    q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "    # attn shape:[B_, num_heads, N, N]\n",
        "    attn = tf.matmul(q, k, transpose_b=True) * self.scale\n",
        "\n",
        "    # rel_emb shape:[N, N, num_heads]\n",
        "    rel_emb = tf.gather(self.rel_pos_bias, self.rel_pos)\n",
        "    # rel_emb shape:[num_heads, N, N]\n",
        "    rel_emb = tf.transpose(rel_emb, perm=[2, 0, 1])\n",
        "    # rel_emb shape:[1, num_heads, N, N]\n",
        "    rel_emb = tf.reshape(rel_emb, shape=[1, self.num_heads, N, N])\n",
        "\n",
        "    attn = tf.nn.softmax(attn + rel_emb, axis=-1)\n",
        "\n",
        "    # attn shape:[B_, num_heads, N, head_dims]\n",
        "    attn = attn @ v\n",
        "\n",
        "    attn = tf.transpose(attn, perm=[0, 2, 1, 3])\n",
        "    attn = tf.reshape(attn, shape=[B_, N, self.C])\n",
        "\n",
        "    attn = self.dense(attn)\n",
        "\n",
        "    # attn shape:[B_, N, C]\n",
        "    return attn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwoDrbAPTt7C"
      },
      "outputs": [],
      "source": [
        "class block_attention(tfla.Layer):\n",
        "  def __init__(self, H, W, window_size, C, num_heads):\n",
        "    super().__init__()\n",
        "    self.H = H\n",
        "    self.W = W\n",
        "    self.window_size = window_size\n",
        "    self.C = C\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.norm1 = tfla.LayerNormalization(epsilon=1e-6)\n",
        "    self.norm2 = tfla.LayerNormalization(epsilon=1e-6)\n",
        "    self.fc1 = tfla.Dense(4 * C, activation=\"gelu\")\n",
        "    self.fc2 = tfla.Dense(C)\n",
        "    self.window_attention = window_attention(window_size, C, num_heads)\n",
        "\n",
        "  def call(self, x):\n",
        "    # x shape:[B, H, W, C]\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "\n",
        "    # window_partition_x shape:[B_, window_size, window_size, C]\n",
        "    window_partition_x = window_partition(x, self.window_size)\n",
        "    # window_attention_x shape:[B_, N, C]\n",
        "    window_attention_x = self.window_attention(window_partition_x)\n",
        "    # window_attention_x shape:[B_, window_size, window_size, C]\n",
        "    window_attention_x = tf.reshape(window_attention_x, shape=[-1, self.window_size, self.window_size, self.C])\n",
        "    # window_attention_x shape:[B, H, W, C]\n",
        "    window_attention_x = window_reverse(window_attention_x, self.window_size, self.H, self.W)\n",
        "\n",
        "    x = shortcut + window_attention_x\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    x = x + shortcut\n",
        "\n",
        "    # return shape:[B, H, W, C]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc9EPEI7wlBx"
      },
      "outputs": [],
      "source": [
        "def grid_partition(x, H, W, window_size):\n",
        "  # x shape:[B, H, W, C]\n",
        "  actual_window_size_x = H // window_size\n",
        "  actual_window_size_y = W // window_size\n",
        "  num_windows_x = H // actual_window_size_x\n",
        "  num_windows_y = W // actual_window_size_y\n",
        "  C = tf.shape(x)[3]\n",
        "\n",
        "  # x shape:[B, num_windows_x, row_in_window, num_windows_y, col_in_window, C]\n",
        "  x = tf.reshape(x, shape=[-1, num_windows_x, actual_window_size_x, num_windows_y, actual_window_size_y, C])\n",
        "\n",
        "  # x shape:[B, row_in_window, col_in_window, num_windows_x, num_windows_y, C]\n",
        "  x = tf.transpose(x, perm=[0, 2, 4, 1, 3, 5])\n",
        "\n",
        "  x = tf.reshape(x, shape=[-1, window_size, window_size, C])\n",
        "\n",
        "  # return shape[B_, window_size, window_size, C]\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5QDmroh8HtM"
      },
      "outputs": [],
      "source": [
        "def reverse_grid_partition(x, H, W, window_size):\n",
        "  # x shape:[B_, N, C]\n",
        "  C = tf.shape(x)[2]\n",
        "  actual_window_size_x = H // window_size\n",
        "  actual_window_size_y = W // window_size\n",
        "\n",
        "  # x shape:[B, window_size, window_size, C]\n",
        "  x = tf.reshape(x, shape=[-1, window_size, window_size, C])\n",
        "  x = tf.reshape(x, shape=[-1, actual_window_size_x, actual_window_size_y, window_size, window_size, C])\n",
        "  x = tf.transpose(x, perm=[0, 3, 1, 4, 2, 5])\n",
        "  x = tf.reshape(x, shape=[-1, H, W, C])\n",
        "\n",
        "  # return shape:[B, H, W, C]\n",
        "  return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWRVAwTq9XGV"
      },
      "outputs": [],
      "source": [
        "class grid_attention(tfla.Layer):\n",
        "  def __init__(self, H, W, window_size, C, num_heads):\n",
        "    super().__init__()\n",
        "    self.H = H\n",
        "    self.W = W\n",
        "    self.window_size = window_size\n",
        "    self.C = C\n",
        "    self.num_heads = num_heads\n",
        "\n",
        "    self.norm1 = tfla.LayerNormalization(epsilon=1e-6)\n",
        "    self.norm2 = tfla.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    self.window_attention = window_attention(window_size, C, num_heads)\n",
        "\n",
        "    self.fc1 = tfla.Dense(4 * C, activation=\"gelu\")\n",
        "    self.fc2 = tfla.Dense(C)\n",
        "\n",
        "  def call(self, x):\n",
        "    # x shape:[B, H, W, C]\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm1(x)\n",
        "\n",
        "    grid_partition_x = grid_partition(x, self.H, self.W, self.window_size)\n",
        "    grid_attention_x = self.window_attention(grid_partition_x)\n",
        "    # grid_attention_x shape:[B, H, W, C]\n",
        "    grid_attention_x = reverse_grid_partition(grid_attention_x, self.H, self.W, self.window_size)\n",
        "\n",
        "    x = shortcut + grid_attention_x\n",
        "\n",
        "    shortcut = x\n",
        "    x = self.norm2(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    x = shortcut + x\n",
        "\n",
        "    # return shape:[B, H, W, C]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEbP7t7b_0mM"
      },
      "outputs": [],
      "source": [
        "class MBConv(tfla.Layer):\n",
        "  def __init__(self, C, out_channels, downsample):\n",
        "    super().__init__()\n",
        "    self.C = C\n",
        "    self.out_channels = out_channels\n",
        "    self.downsample = downsample\n",
        "\n",
        "    self.shortcut = tfla.Conv2D(out_channels, kernel_size=1, strides=1, use_bias=False)\n",
        "    self.expansion = tfla.Conv2D(4 * C, kernel_size=1, strides=1, padding=\"same\", use_bias=False)\n",
        "    self.bn1 = tfla.BatchNormalization()\n",
        "    self.gelu1 = tfla.Activation(\"gelu\")\n",
        "    self.depthwiseds = tfla.DepthwiseConv2D(3, strides=2, padding=\"same\", use_bias=False)\n",
        "    self.depthwise = tfla.DepthwiseConv2D(3, strides=1, padding=\"same\", use_bias=False)\n",
        "    self.globalaverage = tfla.GlobalAveragePooling2D()\n",
        "    self.dense1 = tfla.Dense(C, activation=\"gelu\")\n",
        "    self.dense2 = tfla.Dense(4 * C, activation=\"sigmoid\")\n",
        "    self.conv1 = tfla.Conv2D(out_channels, kernel_size=1, strides=1, padding=\"same\", use_bias=False)\n",
        "    self.bn2 = tfla.BatchNormalization()\n",
        "    self.bn3 = tfla.BatchNormalization()\n",
        "    self.gelu2 = tfla.Activation(\"gelu\")\n",
        "    self.shortcutglo = tfla.AveragePooling2D(pool_size=2, strides=2)\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    super().build(input_shape)\n",
        "\n",
        "  def call(self, x):\n",
        "  # x shape:[B, H, W, C]\n",
        "\n",
        "    if(self.downsample):\n",
        "      shortcut = self.shortcutglo(x)\n",
        "      shortcut = self.shortcut(shortcut)\n",
        "    else:\n",
        "      shortcut = self.shortcut(x)\n",
        "\n",
        "    x = self.expansion(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.gelu1(x)\n",
        "    if(self.downsample):\n",
        "      x = self.depthwiseds(x)\n",
        "    else:\n",
        "      x = self.depthwise(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.gelu2(x)\n",
        "\n",
        "    sne = self.globalaverage(x)\n",
        "    sne = self.dense1(sne)\n",
        "    sne = self.dense2(sne)\n",
        "    sne = tf.expand_dims(sne, axis=1)\n",
        "    sne = tf.expand_dims(sne, axis=1)\n",
        "\n",
        "    x = x * sne\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn3(x)\n",
        "\n",
        "    return x + shortcut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzVjcIut_K29"
      },
      "outputs": [],
      "source": [
        "inputs = tfla.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = tfla.Conv2D(64, kernel_size=3, strides=2, padding=\"same\", use_bias=False)(inputs)\n",
        "x = tfla.Conv2D(64, kernel_size=3, strides=2, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "# block 1\n",
        "# x shape:[B, 56, 56, 64]\n",
        "x = MBConv(C=64, out_channels=64, downsample=False)(x)\n",
        "x = block_attention(H=56, W=56, window_size=7, C=64, num_heads=2)(x)\n",
        "x = grid_attention(H=56, W=56, window_size=7, C=64, num_heads=2)(x)\n",
        "x = MBConv(C=64, out_channels=64, downsample=False)(x)\n",
        "x = block_attention(H=56, W=56, window_size=7, C=64, num_heads=2)(x)\n",
        "x = grid_attention(H=56, W=56, window_size=7, C=64, num_heads=2)(x)\n",
        "\n",
        "# block 2\n",
        "# x shape:[B, 28, 28, 128]\n",
        "x = MBConv(C=64, out_channels=128, downsample=True)(x)\n",
        "x = block_attention(H=28, W=28, window_size=7, C=128, num_heads=4)(x)\n",
        "x = grid_attention(H=28, W=28, window_size=7, C=128, num_heads=4)(x)\n",
        "x = MBConv(C=128, out_channels=128, downsample=False)(x)\n",
        "x = block_attention(H=28, W=28, window_size=7, C=128, num_heads=4)(x)\n",
        "x = grid_attention(H=28, W=28, window_size=7, C=128, num_heads=4)(x)\n",
        "\n",
        "# block 3\n",
        "# x shape:[B, 14, 14, 256]\n",
        "x = MBConv(C=128, out_channels=256, downsample=True)(x)\n",
        "x = block_attention(H=14, W=14, window_size=7, C=256, num_heads=8)(x)\n",
        "x = grid_attention(H=14, W=14, window_size=7, C=256, num_heads=8)(x)\n",
        "for _ in range(4):\n",
        "  x = MBConv(C=256, out_channels=256, downsample=False)(x)\n",
        "  x = block_attention(H=14, W=14, window_size=7, C=256, num_heads=8)(x)\n",
        "  x = grid_attention(H=14, W=14, window_size=7, C=256, num_heads=8)(x)\n",
        "\n",
        "# block 4\n",
        "# x shape:[B, 7, 7, 512]\n",
        "x = MBConv(C=256, out_channels=512, downsample=True)(x)\n",
        "x = block_attention(H=7, W=7, window_size=7, C=512, num_heads=16)(x)\n",
        "x = grid_attention(H=7, W=7, window_size=7, C=512, num_heads=16)(x)\n",
        "x = MBConv(C=512, out_channels=512, downsample=False)(x)\n",
        "x = block_attention(H=7, W=7, window_size=7, C=512, num_heads=16)(x)\n",
        "x = grid_attention(H=7, W=7, window_size=7, C=512, num_heads=16)(x)\n",
        "\n",
        "x = tfla.GlobalAveragePooling2D()(x)\n",
        "outputs = tfla.Dense(200, activation=\"softmax\")(x)\n",
        "\n",
        "model = tfm.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v48xPWr7J9kW",
        "outputId": "fc98e680-bb2b-4d6e-88fc-81fe9d964e14"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,728</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,864</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,322</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,322</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,560</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_1               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,322</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,322</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">95,296</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_2               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">198,948</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">198,948</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">288,384</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_3               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">198,948</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">198,948</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">370,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_4               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,133,824</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_5               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,133,824</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_6               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,133,824</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_7               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,133,824</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_8               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_8                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">791,112</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,462,528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_9               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_9                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MBConv</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,495,872</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_10              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">block_attention</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,088</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">grid_attention</span>)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_11     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,600</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,728\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,864\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv (\u001b[38;5;33mMBConv\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m50,322\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention (\u001b[38;5;33mgrid_attention\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m50,322\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_1 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m74,560\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_1               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m50,322\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m50,322\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_2 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m95,296\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_2               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m198,948\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m198,948\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_3 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m288,384\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_3               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m198,948\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m198,948\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_4 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m370,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_4               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_5 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m1,133,824\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_5               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_6 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m1,133,824\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_6               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_7 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m1,133,824\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_7               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_8 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m1,133,824\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_8               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_8                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m791,112\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_9 (\u001b[38;5;33mMBConv\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m1,462,528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_9               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,155,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_9                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,155,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ mb_conv_10 (\u001b[38;5;33mMBConv\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m4,495,872\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ block_attention_10              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,155,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mblock_attention\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ grid_attention_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │     \u001b[38;5;34m3,155,088\u001b[0m │\n",
              "│ (\u001b[38;5;33mgrid_attention\u001b[0m)                │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d_11     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_110 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m102,600\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,067,056</span> (126.14 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,067,056\u001b[0m (126.14 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,025,840</span> (125.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,025,840\u001b[0m (125.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> (161.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m41,216\u001b[0m (161.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K75mr863LF8r"
      },
      "outputs": [],
      "source": [
        "steps_per_epoch = 3128\n",
        "epochs = 40\n",
        "total_steps = steps_per_epoch * epochs\n",
        "\n",
        "lr = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    initial_learning_rate=5e-4,\n",
        "    decay_steps=total_steps\n",
        ")\n",
        "\n",
        "opt = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=5e-2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw_JBekqLIWP",
        "outputId": "895bfc65-808b-4f42-d5a6-a82511a05bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1936s\u001b[0m 537ms/step - accuracy: 0.0690 - loss: 5.1043\n",
            "Epoch 2/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1565s\u001b[0m 495ms/step - accuracy: 0.2140 - loss: 3.9878\n",
            "Epoch 3/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1566s\u001b[0m 496ms/step - accuracy: 0.2904 - loss: 3.6471\n",
            "Epoch 4/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1566s\u001b[0m 496ms/step - accuracy: 0.3552 - loss: 3.3693\n",
            "Epoch 5/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1566s\u001b[0m 496ms/step - accuracy: 0.4125 - loss: 3.1247\n",
            "Epoch 6/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.4633 - loss: 2.9242\n",
            "Epoch 7/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 497ms/step - accuracy: 0.5086 - loss: 2.7546\n",
            "Epoch 8/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 496ms/step - accuracy: 0.5483 - loss: 2.6045\n",
            "Epoch 9/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.5859 - loss: 2.4701\n",
            "Epoch 10/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 497ms/step - accuracy: 0.6196 - loss: 2.3561\n",
            "Epoch 11/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 496ms/step - accuracy: 0.6518 - loss: 2.2501\n",
            "Epoch 12/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.6800 - loss: 2.1562\n",
            "Epoch 13/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.7086 - loss: 2.0661\n",
            "Epoch 14/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 496ms/step - accuracy: 0.7339 - loss: 1.9893\n",
            "Epoch 15/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 497ms/step - accuracy: 0.7577 - loss: 1.9198\n",
            "Epoch 16/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 497ms/step - accuracy: 0.7819 - loss: 1.8466\n",
            "Epoch 17/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 497ms/step - accuracy: 0.8010 - loss: 1.7958\n",
            "Epoch 18/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.8172 - loss: 1.7449\n",
            "Epoch 19/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.8371 - loss: 1.6911\n",
            "Epoch 20/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 496ms/step - accuracy: 0.8497 - loss: 1.6517\n",
            "Epoch 21/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 497ms/step - accuracy: 0.8646 - loss: 1.6104\n",
            "Epoch 22/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 497ms/step - accuracy: 0.8754 - loss: 1.5768\n",
            "Epoch 23/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 497ms/step - accuracy: 0.8852 - loss: 1.5448\n",
            "Epoch 24/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1573s\u001b[0m 498ms/step - accuracy: 0.8936 - loss: 1.5171\n",
            "Epoch 25/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 496ms/step - accuracy: 0.9026 - loss: 1.4896\n",
            "Epoch 26/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1572s\u001b[0m 498ms/step - accuracy: 0.9105 - loss: 1.4640\n",
            "Epoch 27/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1570s\u001b[0m 497ms/step - accuracy: 0.9158 - loss: 1.4438\n",
            "Epoch 28/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 497ms/step - accuracy: 0.9218 - loss: 1.4240\n",
            "Epoch 29/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9279 - loss: 1.4026\n",
            "Epoch 30/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9328 - loss: 1.3828\n",
            "Epoch 31/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1569s\u001b[0m 497ms/step - accuracy: 0.9364 - loss: 1.3681\n",
            "Epoch 32/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9402 - loss: 1.3549\n",
            "Epoch 33/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 497ms/step - accuracy: 0.9434 - loss: 1.3419\n",
            "Epoch 34/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9451 - loss: 1.3341\n",
            "Epoch 35/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9477 - loss: 1.3228\n",
            "Epoch 36/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 497ms/step - accuracy: 0.9487 - loss: 1.3182\n",
            "Epoch 37/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9500 - loss: 1.3140\n",
            "Epoch 38/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1567s\u001b[0m 496ms/step - accuracy: 0.9503 - loss: 1.3125\n",
            "Epoch 39/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1566s\u001b[0m 496ms/step - accuracy: 0.9509 - loss: 1.3089\n",
            "Epoch 40/40\n",
            "\u001b[1m3128/3128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 496ms/step - accuracy: 0.9513 - loss: 1.3046\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    combined_ds,\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hNK8S124LJmL",
        "outputId": "8932092a-c0b1-48e5-95d7-bb8d937b9d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 581ms/step - accuracy: 0.6913 - loss: 1.6756\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.6835989952087402, 0.6927000284194946]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6mm0Cm8OLLBt"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train'], loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}